{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "from subprocess import check_call\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.general_utils import *\n",
    "from utils.unlearn_utils import *\n",
    "import utils.MIA_utils as mia\n",
    "import datasets\n",
    "import backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "transform_train, transform_test = get_std_transforms(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of forget samples: 1000\n",
      "Number of selected samples: 1000\n"
     ]
    }
   ],
   "source": [
    "model_type = 'smallvgg'\n",
    "\n",
    "forget_range = [[0, 100]]*10\n",
    "\n",
    "forget_train_noaug = datasets.UnlearnCIFAR10(root='/home/hoangtuan/data', transform=transform_test, \n",
    "                                                 download=True, data_set='train', data_section='forget',\n",
    "                                                 forget_range=forget_range)\n",
    "forget_train_noaug_loader = DataLoader(forget_train_noaug, shuffle=False, num_workers=6, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(ckp_folder, dataloader, model_type):\n",
    "    ckp_file = f'{ckp_folder}/ckp.pth'\n",
    "    if not os.path.isfile(ckp_file):\n",
    "        ckp_file = f'{folder}/ckp.pt'\n",
    "    ckp = torch.load(ckp_file)\n",
    "    if model_type == 'smallvgg':\n",
    "        model = backbone.SmallVGG(num_classes=10, dropout=0.5)\n",
    "        fea_dict = {'classifier.4': 'output'}\n",
    "    elif model_type == 'allcnn':\n",
    "        model = backbone.AllCNN(num_classes=10, dropout=False)\n",
    "        fea_dict = {'classifier.0': 'output'}\n",
    "    model.load_state_dict(ckp['model'])\n",
    "    model.eval()\n",
    "    model.cuda();\n",
    "    \n",
    "    # print(get_graph_node_names(model))\n",
    "    feas, labels = extract_features(model, dataloader, fea_dict)\n",
    "    outputs = torch.cat(feas['output'])\n",
    "\n",
    "    torch.save(outputs, f'{ckp_folder}/outputs_{len(labels)}.pth')\n",
    "    print(f'{folder}         ', end='\\r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1:\n",
    "Train 50 models with full-training dataset (Positive) and retaining dataset only (Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 51):\n",
    "    os.makedirs(f'exp/learned/smallvgg_cifar10/full_data_MIA/exp{i:02d}/', exist_ok=True)\n",
    "    shutil.copy('exp/learned/smallvgg_cifar10/full_data/config.yaml', f'exp/learned/smallvgg_cifar10/full_data_MIA/exp{i:02d}/config.yaml')\n",
    "    check_call(['python3', 'train.py',  f'exp/learned/smallvgg_cifar10/full_data_MIA/exp{i:02d}/config.yaml'], shell=False)\n",
    "\n",
    "    os.makedirs(f'exp/learned/smallvgg_cifar10/forget_0-100_10classes_MIA/exp{i:02d}/', exist_ok=True)\n",
    "    shutil.copy('exp/learned/smallvgg_cifar10/forget_0-100_10classes/config.yaml',\n",
    "                f'exp/learned/smallvgg_cifar10/forget_0-100_10classes_MIA/exp{i:02d}/config.yaml')\n",
    "    check_call(['python3', 'train.py', f'exp/learned/smallvgg_cifar10/forget_0-100_10classes_MIA/exp{i:02d}/config.yaml'], shell=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(46, 51):\n",
    "    os.makedirs(f'exp/unlearned/smallvgg_cifar10/data_removal/MIA/exp{i:02d}', exist_ok=True)\n",
    "    shutil.copy( 'exp/unlearned/smallvgg_cifar10/exp0/config.yaml',\n",
    "                f'exp/unlearned/smallvgg_cifar10/data_removal/MIA/exp{i:02d}/config.yaml')\n",
    "    check_call(['python3', 'unlearn.py', f'exp/unlearned/smallvgg_cifar10/data_removal/MIA/exp{i:02d}/config.yaml'], shell=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Extracting features and train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# checkpoints for models trained on retaining dataset only (negative) and models trained on full dataset (positive)\n",
    "for ckp_folder in ['forget_0-100_10classes_MIA', 'full_data_MIA']: \n",
    "    for i in range(1, 51):\n",
    "        extract_feature(f'exp/learned/{model_type}_cifar10/{ckp_folder}/exp{i:02d}/checkpoints', forget_train_noaug_loader, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (80000, 20) (80000,)\n",
      "Val:   (10000, 20) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_feas, train_labels = [], []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    for folder in ['full_data_MIA', 'forget_0-100_10classes_MIA']:\n",
    "        \n",
    "        labels = torch.tensor(all_forget_train_noaug.selected_targets)\n",
    "        oh_labels = F.one_hot(labels, num_classes=10)\n",
    "        outputs   = torch.load(f'exp/learned/{model}_cifar10/{folder}/exp{i:02d}/checkpoints/outputs_{len(labels)}.pth')\n",
    "\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        feas = torch.cat([outputs, oh_labels], dim=1)\n",
    "        if folder == 'full_data_MIA':\n",
    "            labels = torch.ones(len(labels))\n",
    "        else:\n",
    "            labels = torch.zeros(len(labels))\n",
    "\n",
    "        if len(train_feas) == 0:\n",
    "            train_feas = feas\n",
    "            train_labels = labels\n",
    "        else:\n",
    "            train_feas = torch.cat([train_feas, feas], dim=0)\n",
    "            train_labels = torch.cat([train_labels, labels], dim=0)\n",
    "\n",
    "datasize = len(train_labels)\n",
    "# validation set\n",
    "val_feas = train_feas[-2*(datasize//10):-datasize//10].numpy()\n",
    "val_labels = train_labels[-2*(datasize//10):-datasize//10].numpy()\n",
    "# test set\n",
    "test_feas = train_feas[-datasize//10:].numpy()\n",
    "test_labels = train_labels[-datasize//10:].numpy()\n",
    "# training set\n",
    "train_feas = train_feas[:-2*datasize//10].numpy()\n",
    "train_labels = train_labels[:-2*datasize//10].numpy()\n",
    "idx = np.random.permutation(len(train_labels))\n",
    "train_feas = train_feas[idx]\n",
    "train_labels = train_labels[idx]\n",
    "\n",
    "print(f'Train: {train_feas.shape} {train_labels.shape}')\n",
    "print(f'Val:   {val_feas.shape} {val_labels.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to fine-tune the following parameters\n",
    "best_param = {'max_depth': 10, 'subsample': 0.8, 'reg_lambda': 10, 'min_child_weight': 0.1}\n",
    "clf = XGBClassifier(learning_rate=0.2, **best_param)\n",
    "\n",
    "clf.fit(train_feas, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on validation dataset\n",
    "val_pred_prob = clf.predict_proba(val_feas)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(val_labels, val_pred_prob[:, 1])\n",
    "f1_scores = 2*recall*precision/(recall+precision)\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(f'AUC: {auc:.04f}')\n",
    "plt.plot(recall, precision)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on training dataset\n",
    "train_pred_prob = clf.predict_proba(train_feas)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(train_labels, train_pred_prob[:, 1])\n",
    "f1_scores = 2*recall*precision/(recall+precision)\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(f'AUC: {auc:.04f}')\n",
    "plt.plot(recall, precision)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features of unlearnt model\n",
    "for i in range(46, 51):\n",
    "    folder = f'exp/unlearned/{model_type}_cifar10/data_removal/MIA/exp{i:02d}/results/0-100_10classes/ckp'\n",
    "    extract_feature(folder, forget_train_noaug_loader, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_features(pos_folder, neg_folder, idx_range=[46, 51]):\n",
    "    feas, labels = [], []\n",
    "    lbls = torch.tensor(forget_train_noaug.selected_targets)\n",
    "    oh_labels = F.one_hot(lbls, num_classes=10)\n",
    "    for i in range(idx_range[0], idx_range[1]):\n",
    "        outputs = torch.load(pos_folder.replace('exp__', f'exp{i}'))\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        fea = torch.cat([outputs, oh_labels], dim=1)\n",
    "        feas.append(fea)\n",
    "        labels.append(torch.ones(len(fea)))\n",
    "\n",
    "        outputs = torch.load(neg_folder.replace('exp__', f'exp{i}'))\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        fea = torch.cat([outputs, oh_labels], dim=1)\n",
    "        feas.append(fea)\n",
    "        labels.append(torch.zeros(len(fea)))\n",
    "\n",
    "    feas = torch.cat(feas).numpy()\n",
    "    labels = torch.cat(labels).numpy()\n",
    "\n",
    "    return feas, labels        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "neg_folder = f'exp/learned/{model_type}_cifar10/forget_0-100_10classes/MIA/exp__/checkpoints/outputs_{len(labels)}.pth'\n",
    "\n",
    "pos_folder = f'exp/unlearned/{model_type}_cifar10/data_removal/MIA/exp__/results/0-100_10classes/ckp/outputs_{len(labels)}.pth'\n",
    "feas_s1, labels_s1 = get_test_features(pos_folder, neg_folder, idx_range=[47, 49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia.plot_prec_recall(clf, ([test_feas, test_labels, 'Test'], # No unlearnt\n",
    "                           [feas_s1, labels_s1, 'S1'],       # target result\n",
    "                           ),\n",
    "                           save=False\n",
    "                           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "continual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49b9b44b0517eb1b3c1d232b09afd009474c507b22b051d010ae3e514786da14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
